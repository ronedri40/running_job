import asyncio
import logging
from collections import deque
from dataclasses import dataclass, field
from typing import Dict, List, Any, Set
from .http_engine import HttpEngine

logger = logging.getLogger(__name__)

@dataclass
class AgentConfig:
    name: str
    request_url: str
    concurrency: int
    batch_size: int
    timeout_sec: int

@dataclass
class JobContext:
    job_id: str
    agent_name: str
    items: deque
    params: Dict[str, Any]
    callbacks: Any
    batch_size: int
    url: str
    timeout: int
    active_batches: int = 0
    processed_count: int = 0
    lock: asyncio.Lock = field(default_factory=asyncio.Lock)
    done_evt: asyncio.Event = field(default_factory=asyncio.Event)

class Dispatcher:
    def __init__(self, agent_configs: Dict[str, AgentConfig], http_engine: HttpEngine):
        self.configs = agent_configs
        self.http_engine = http_engine
        self.rotations: Dict[str, deque[JobContext]] = {n: deque() for n in agent_configs}
        self.semaphores: Dict[str, asyncio.Semaphore] = {
            n: asyncio.Semaphore(c.concurrency) for n, c in agent_configs.items()
        }
        self.cancel_flags: Set[str] = set()
        self._managers: List[asyncio.Task] = []
        self._running = False

    async def start(self):
        logger.info("Starting Dispatcher...")
        self._running = True
        for name in self.configs:
            self._managers.append(asyncio.create_task(self._agent_manager(name)))
            logger.info(f"Started manager for agent: {name} (Concurrency: {self.configs[name].concurrency})")

    async def stop(self):
        logger.info("Stopping Dispatcher...")
        self._running = False
        for t in self._managers:
            t.cancel()
        await asyncio.gather(*self._managers, return_exceptions=True)
        logger.info("Dispatcher stopped.")

    async def submit(self, ctx: JobContext):
        logger.info(f"[{ctx.job_id}] Submitted to agent '{ctx.agent_name}' with {len(ctx.items)} items")
        self.rotations[ctx.agent_name].append(ctx)

    def mark_for_cancel(self, job_id: str):
        logger.info(f"[{job_id}] Marked for cancellation")
        self.cancel_flags.add(job_id)

    async def _agent_manager(self, agent_name: str):
        sem = self.semaphores[agent_name]
        rotation = self.rotations[agent_name]
        
        logger.debug(f"Manager loop started for {agent_name}")

        while self._running:
            if not rotation:
                await asyncio.sleep(0.05)
                continue

            # Wait for available slot
            await sem.acquire()

            # Pick next job (Fairness)
            ctx = rotation.popleft()
            
            # Spawn worker
            asyncio.create_task(self._run_batch_step(ctx, sem, rotation))

    async def _run_batch_step(self, ctx: JobContext, sem: asyncio.Semaphore, rotation: deque):
        batch_items = []
        sem_released = False
        
        try:
            async with ctx.lock:
                # 1. Check Cancel
                if ctx.job_id in self.cancel_flags:
                    logger.info(f"[{ctx.job_id}] Cancellation detected during batch prep")
                    if not ctx.done_evt.is_set():
                        await ctx.callbacks.on_job_canceled(
                            ctx.job_id, ctx.agent_name, ctx.processed_count, "Canceled by User"
                        )
                        ctx.done_evt.set()
                    sem.release()
                    return

                # 2. Pop Batch
                for _ in range(ctx.batch_size):
                    if not ctx.items: break
                    batch_items.append(ctx.items.popleft())

                if not batch_items:
                    sem.release()
                    return

                ctx.active_batches += 1
                
                # 3. Rotate
                if ctx.items:
                    rotation.append(ctx)

            # 4. Process
            # We assume batch_index 0 for log clarity since we aren't tracking absolute index in this specific logic
            # (You could add a 'current_batch_index' to ctx if strict indexing is needed)
            logger.debug(f"[{ctx.job_id}] Processing batch of size {len(batch_items)}")
            
            try:
                res = await self.http_engine.process_batch(
                    ctx.url, 
                    {
                        "job_id": ctx.job_id, 
                        "agent_name": ctx.agent_name, 
                        "items": batch_items, 
                        "params": ctx.params
                    }, 
                    ctx.timeout
                )
            finally:
                sem.release()
                sem_released = True

            # 5. Finalize
            async with ctx.lock:
                ctx.active_batches -= 1
                ctx.processed_count += len(batch_items)
                
                await ctx.callbacks.on_batch_done(
                    ctx.job_id, ctx.agent_name, 0, len(batch_items), res
                )

                if not ctx.items and ctx.active_batches == 0 and not ctx.done_evt.is_set():
                    logger.info(f"[{ctx.job_id}] Job Finished. Total Processed: {ctx.processed_count}")
                    await ctx.callbacks.on_job_done(
                        ctx.job_id, ctx.agent_name, ctx.processed_count, "Success"
                    )
                    ctx.done_evt.set()
                    self.cancel_flags.discard(ctx.job_id)

        except Exception as e:
            logger.error(f"[{ctx.job_id}] Unexpected error in batch: {e}", exc_info=True)
            if not sem_released:
                sem.release()
            
            async with ctx.lock:
                if not ctx.done_evt.is_set():
                    await ctx.callbacks.on_job_failed(
                        ctx.job_id, ctx.agent_name, ctx.processed_count, str(e)
                    )
                    ctx.done_evt.set()
